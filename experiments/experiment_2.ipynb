{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Template Prompt Transfer with Genetic Algorithms\n",
    "\n",
    "## Goal\n",
    "Transfer prompt style from a reference image to a target model, evolving structured prompts.\n",
    "\n",
    "## Methodology\n",
    "- **Genome**: BlockGenome (subject + composition + lighting + style + quality + negative)\n",
    "- **Fitness**: w1 * CLIP_score + w2 * LPIPS_similarity (to reference)\n",
    "- **Reference**: High-quality image whose style/structure we want to replicate\n",
    "- **Target Model**: qwen-image (Fal AI)\n",
    "- **LLM Seeding**: Use Gemini to analyze reference and generate initial seeds\n",
    "\n",
    "## Sub-experiments\n",
    "- **2.1 Static Weights**: Fixed CLIP=0.5, LPIPS=0.5 throughout evolution\n",
    "- **2.2 Adaptive Weights**: CLIP weight increases from 0.3 → 0.6 over generations\n",
    "  - Early: Focus on structure matching (LPIPS)\n",
    "  - Later: Focus on content alignment (CLIP)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0: Install Dependencies\n",
    "\n",
    "Run this cell first to ensure all required packages are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ lpips is already installed\n",
      "✓ transformers is already installed\n",
      "✓ torch is already installed\n",
      "✓ torchvision is already installed\n",
      "\n",
      "All dependencies ready!\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies for Experiment 2\n",
    "# LPIPS is required for perceptual similarity scoring\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package, pip_name=None):\n",
    "    \"\"\"Install package if not already installed.\"\"\"\n",
    "    pip_name = pip_name or package\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✓ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pip_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name, \"-q\"])\n",
    "        print(f\"✓ {pip_name} installed successfully\")\n",
    "\n",
    "# Install lpips (Learned Perceptual Image Patch Similarity)\n",
    "install_if_missing(\"lpips\")\n",
    "\n",
    "# Other dependencies that should already be installed\n",
    "install_if_missing(\"transformers\")\n",
    "install_if_missing(\"torch\")\n",
    "install_if_missing(\"torchvision\")\n",
    "\n",
    "print(\"\\nAll dependencies ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete.\n",
      "Random seed: 42\n",
      "Working directory: /Users/dogukantopcu/Desktop/jobs/hubx/projects/epe-image-generation-v4/evolutionary-prompt-engineering/experiments\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "# Add parent directory to path for src imports\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Project imports - Block-based genome and evolution (v2)\n",
    "from src.genome_v2 import BlockGenome, BlockGenomeFactory\n",
    "from src.evolution_v2 import BlockGeneticOperators, BlockEvolutionEngine\n",
    "from src.fitness_v2 import TemplateFitnessEvaluator, AdaptiveTemplateFitnessEvaluator\n",
    "from src.models import get_model\n",
    "from src.llm_prompt_generator import get_prompt_generator, GeminiPromptGenerator, DummyPromptGenerator\n",
    "from src.vocabulary_manager import VocabularyManager\n",
    "from src.utils import (\n",
    "    create_block_vocabularies,\n",
    "    save_json,\n",
    "    Logger\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Configure matplotlib for publication-quality plots\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'legend.fontsize': 11,\n",
    "    'figure.figsize': (10, 6),\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight'\n",
    "})\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Environment setup complete.\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT PARAMETERS (ENHANCED)\n",
    "# =============================================================================\n",
    "\n",
    "# Subject transfer: User's desired subject (different from reference)\n",
    "USER_SUBJECT = \"a professional product photo of a car\"\n",
    "\n",
    "# Evolution parameters - INCREASED for better results\n",
    "POPULATION_SIZE = 15\n",
    "MAX_GENERATIONS = 50  # Increased from 20 to 50\n",
    "ELITE_SIZE = 2\n",
    "MUTATION_RATE = 0.5  # Slightly increased\n",
    "ADD_PROBABILITY = 0.35\n",
    "REMOVE_PROBABILITY = 0.2\n",
    "\n",
    "# Vocabulary Manager parameters\n",
    "USE_VOCABULARY_MANAGER = True  # Enable LLM-based adaptive vocabulary\n",
    "VOCAB_INITIAL_SIZE = 1000  # Target size for initial vocabulary\n",
    "VOCAB_EXPANSION_SIZE = 50  # New modifiers to add per expansion\n",
    "VOCAB_PRUNE_THRESHOLD = 20  # Generations before pruning unused modifiers\n",
    "VOCAB_EXPANSION_INTERVAL = 5  # Expand vocabulary every N generations\n",
    "VOCAB_PRUNE_INTERVAL = 10  # Prune vocabulary every N generations\n",
    "\n",
    "# Genome constraints - EXPANDED search space\n",
    "MAX_ITEMS_PER_BLOCK = 5  # Increased from 3 to 5\n",
    "\n",
    "# =============================================================================\n",
    "# FITNESS WEIGHTS\n",
    "# =============================================================================\n",
    "\n",
    "# Static weights (Experiment 2.1)\n",
    "STATIC_CLIP_WEIGHT = 0.5   # Content alignment with user subject\n",
    "STATIC_LPIPS_WEIGHT = 0.5  # Structure similarity to reference\n",
    "\n",
    "# Adaptive weights (Experiment 2.2)\n",
    "# Strategy: Start with structure matching, shift to content alignment\n",
    "INITIAL_CLIP_WEIGHT = 0.3  # Early: prioritize LPIPS (structure)\n",
    "FINAL_CLIP_WEIGHT = 0.6    # Late: prioritize CLIP (content)\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_NAME = \"qwen-image\"  # Supports negative prompts\n",
    "IMAGE_SIZE = \"landscape_4_3\"\n",
    "NUM_INFERENCE_STEPS = 30\n",
    "GUIDANCE_SCALE = 3.5\n",
    "GENERATION_SEED = 42  # Fixed seed for reproducible image generation\n",
    "\n",
    "# =============================================================================\n",
    "# LLM SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "USE_LLM_SEEDING = True  # Set to False to use random seeding (no Gemini required)\n",
    "\n",
    "# =============================================================================\n",
    "# OUTPUT SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_DIR = Path(\"../data/results/experiment_2\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_EVERY_N_GENERATIONS = 5  # Save checkpoints every N generations\n",
    "SAVE_ALL_IMAGES = True  # NEW: Save all generated images\n",
    "\n",
    "# =============================================================================\n",
    "# RESULTS TRACKING\n",
    "# =============================================================================\n",
    "\n",
    "# Global array to store all results\n",
    "ALL_RESULTS = []\n",
    "\n",
    "# Print configuration summary\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2 CONFIGURATION (ENHANCED)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nUser Subject: {USER_SUBJECT}\")\n",
    "print(f\"\\nEvolution Parameters:\")\n",
    "print(f\"  Population Size: {POPULATION_SIZE}\")\n",
    "print(f\"  Max Generations: {MAX_GENERATIONS}\")\n",
    "print(f\"  Elite Size: {ELITE_SIZE}\")\n",
    "print(f\"  Mutation Rate: {MUTATION_RATE}\")\n",
    "print(f\"  Max Items per Block: {MAX_ITEMS_PER_BLOCK}\")\n",
    "print(f\"\\nStatic Weights (Exp 2.1):\")\n",
    "print(f\"  CLIP: {STATIC_CLIP_WEIGHT}, LPIPS: {STATIC_LPIPS_WEIGHT}\")\n",
    "print(f\"\\nAdaptive Weights (Exp 2.2):\")\n",
    "print(f\"  CLIP: {INITIAL_CLIP_WEIGHT} -> {FINAL_CLIP_WEIGHT}\")\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"LLM Seeding: {'Enabled (Gemini)' if USE_LLM_SEEDING else 'Disabled (Random)'}\")\n",
    "print(f\"Save All Images: {SAVE_ALL_IMAGES}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD REFERENCE IMAGE\n",
    "# =============================================================================\n",
    "# The reference image defines the style/structure we want to transfer\n",
    "# to our target subject (USER_SUBJECT)\n",
    "\n",
    "# Option 1: Load from file\n",
    "REFERENCE_IMAGE_PATH = \"../data/reference_images/product_reference.jpg\"\n",
    "\n",
    "# Option 2: Generate a reference image using flux-schnell\n",
    "GENERATE_REFERENCE = True  # Set to False to load from file\n",
    "REFERENCE_PROMPT = \"Professional product photo of a car on a showroom floor, bright studio lighting with soft shadows, clean white background, ultra‑realistic, sharp focus, high detail, minimal reflections\"\n",
    "\n",
    "if GENERATE_REFERENCE:\n",
    "    print(\"Generating reference image using flux-schnell...\")\n",
    "    print(f\"Reference prompt: {REFERENCE_PROMPT}\")\n",
    "    \n",
    "    # Use flux-schnell for reference generation\n",
    "    reference_model = get_model(\"flux-schnell\")\n",
    "    \n",
    "    reference_image, ref_metadata = reference_model.generate(\n",
    "        prompt=REFERENCE_PROMPT,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        num_inference_steps=4,\n",
    "        seed=GENERATION_SEED\n",
    "    )\n",
    "    \n",
    "    # Save reference image\n",
    "    ref_save_path = OUTPUT_DIR / \"reference_image.jpg\"\n",
    "    reference_image.save(ref_save_path)\n",
    "    print(f\"Reference image saved to: {ref_save_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Loading reference image from: {REFERENCE_IMAGE_PATH}\")\n",
    "    if not Path(REFERENCE_IMAGE_PATH).exists():\n",
    "        raise FileNotFoundError(f\"Reference image not found: {REFERENCE_IMAGE_PATH}\")\n",
    "    reference_image = Image.open(REFERENCE_IMAGE_PATH).convert('RGB')\n",
    "    print(f\"Reference image loaded: {reference_image.size}\")\n",
    "\n",
    "# Display reference image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(reference_image)\n",
    "ax.set_title(f\"Reference Image\\n(Style/structure to transfer)\", fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"reference_display.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nReference image size: {reference_image.size}\")\n",
    "print(f\"Target subject: {USER_SUBJECT}\")\n",
    "print(\"\\nGoal: Generate images of the target subject with the style/structure of the reference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE IMAGE GENERATION MODEL\n",
    "# =============================================================================\n",
    "print(\"Initializing image generation model...\")\n",
    "model = get_model(MODEL_NAME)\n",
    "print(f\"  Model: {MODEL_NAME} initialized\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE BLOCK VOCABULARIES\n",
    "# =============================================================================\n",
    "print(\"\\nCreating block vocabularies...\")\n",
    "block_vocabularies = create_block_vocabularies()\n",
    "\n",
    "for block_name, vocab in block_vocabularies.items():\n",
    "    print(f\"  {block_name}: {len(vocab)} terms\")\n",
    "\n",
    "# =============================================================================\n",
    "# INITIALIZE LLM PROMPT GENERATOR\n",
    "# =============================================================================\n",
    "print(\"\\nInitializing prompt generator...\")\n",
    "prompt_generator = get_prompt_generator(use_llm=USE_LLM_SEEDING)\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATE LLM SEEDS (if enabled)\n",
    "# =============================================================================\n",
    "print(\"\\nGenerating LLM seeds from reference image...\")\n",
    "llm_seeds = prompt_generator.generate_seed_prompts(\n",
    "    reference=reference_image,\n",
    "    user_subject=USER_SUBJECT,\n",
    "    population_size=POPULATION_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(llm_seeds)} seed prompts\")\n",
    "print(\"\\nSample seed prompt:\")\n",
    "if llm_seeds:\n",
    "    sample_seed = llm_seeds[0]\n",
    "    for block_name, values in sample_seed.items():\n",
    "        print(f\"  {block_name}: {values}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE GENOME FACTORY\n",
    "# =============================================================================\n",
    "print(\"\\nCreating block genome factory...\")\n",
    "factory = BlockGenomeFactory(\n",
    "    block_vocabularies=block_vocabularies,\n",
    "    max_per_block=MAX_ITEMS_PER_BLOCK\n",
    ")\n",
    "print(f\"  Max items per block: {MAX_ITEMS_PER_BLOCK}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE GENETIC OPERATORS\n",
    "# =============================================================================\n",
    "print(\"\\nCreating genetic operators...\")\n",
    "operators = BlockGeneticOperators(\n",
    "    factory=factory,\n",
    "    mutation_rate=MUTATION_RATE,\n",
    "    add_probability=ADD_PROBABILITY,\n",
    "    remove_probability=REMOVE_PROBABILITY\n",
    ")\n",
    "print(f\"  Mutation rate: {MUTATION_RATE}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE EVOLUTION ENGINE\n",
    "# =============================================================================\n",
    "print(\"\\nCreating evolution engine...\")\n",
    "engine = BlockEvolutionEngine(\n",
    "    factory=factory,\n",
    "    operators=operators,\n",
    "    population_size=POPULATION_SIZE,\n",
    "    elite_size=ELITE_SIZE,\n",
    "    selection_method=\"tournament\",\n",
    "    use_crossover=True  # Enable block crossover\n",
    ")\n",
    "print(f\"  Population size: {POPULATION_SIZE}\")\n",
    "print(f\"  Elite size: {ELITE_SIZE}\")\n",
    "print(f\"  Crossover: Enabled\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE FITNESS EVALUATORS\n",
    "# =============================================================================\n",
    "print(\"\\nCreating fitness evaluators...\")\n",
    "\n",
    "# Static fitness evaluator (Experiment 2.1)\n",
    "static_evaluator = TemplateFitnessEvaluator(\n",
    "    reference_image=reference_image,\n",
    "    clip_weight=STATIC_CLIP_WEIGHT,\n",
    "    lpips_weight=STATIC_LPIPS_WEIGHT\n",
    ")\n",
    "print(f\"  Static Evaluator: CLIP={STATIC_CLIP_WEIGHT}, LPIPS={STATIC_LPIPS_WEIGHT}\")\n",
    "\n",
    "# Adaptive fitness evaluator (Experiment 2.2)\n",
    "adaptive_evaluator = AdaptiveTemplateFitnessEvaluator(\n",
    "    reference_image=reference_image,\n",
    "    initial_clip_weight=INITIAL_CLIP_WEIGHT,\n",
    "    final_clip_weight=FINAL_CLIP_WEIGHT,\n",
    "    max_generations=MAX_GENERATIONS\n",
    ")\n",
    "print(f\"  Adaptive Evaluator: CLIP {INITIAL_CLIP_WEIGHT} -> {FINAL_CLIP_WEIGHT}\")\n",
    "\n",
    "# =============================================================================\n",
    "# INITIALIZE LOGGER\n",
    "# =============================================================================\n",
    "logger = Logger(log_dir=str(OUTPUT_DIR / \"logs\"), name=\"experiment_2\")\n",
    "logger.info(\"Experiment 2 components initialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL COMPONENTS INITIALIZED SUCCESSFULLY\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATE AND EVALUATE BASELINE\n",
    "# =============================================================================\n",
    "# Baseline: Just the subject, no style modifiers\n",
    "\n",
    "print(\"Generating baseline image (subject only, no modifiers)...\")\n",
    "print(f\"Subject: {USER_SUBJECT}\")\n",
    "print()\n",
    "\n",
    "# Create baseline genome (empty blocks)\n",
    "baseline_genome = factory.create_empty(USER_SUBJECT)\n",
    "print(f\"Baseline genome:\")\n",
    "print(f\"  Prompt: {baseline_genome.to_prompt()}\")\n",
    "print(f\"  Negative: {baseline_genome.get_negative_prompt() or '(none)'}\")\n",
    "\n",
    "# Generate baseline image\n",
    "try:\n",
    "    baseline_image, baseline_metadata = model.generate(\n",
    "        prompt=baseline_genome.to_prompt(),\n",
    "        negative_prompt=baseline_genome.get_negative_prompt() or None,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        guidance_scale=GUIDANCE_SCALE,\n",
    "        seed=GENERATION_SEED\n",
    "    )\n",
    "    print(\"\\nBaseline image generated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating baseline image: {e}\")\n",
    "    raise\n",
    "\n",
    "# Evaluate baseline fitness using static evaluator\n",
    "print(\"\\nEvaluating baseline fitness...\")\n",
    "baseline_score = static_evaluator.evaluate(\n",
    "    image=baseline_image,\n",
    "    text=USER_SUBJECT,\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"\\nBaseline Fitness Score: {baseline_score:.4f}\")\n",
    "\n",
    "# Save baseline image\n",
    "baseline_path = OUTPUT_DIR / \"baseline_image.jpg\"\n",
    "baseline_image.save(baseline_path)\n",
    "print(f\"Baseline image saved to: {baseline_path}\")\n",
    "\n",
    "# Display comparison: Reference vs Baseline\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].imshow(reference_image)\n",
    "axes[0].set_title(\"Reference Image\\n(Style to transfer)\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(baseline_image)\n",
    "axes[1].set_title(f\"Baseline Image\\nFitness: {baseline_score:.4f}\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Reference vs Baseline\\nTarget Subject: {USER_SUBJECT[:50]}...\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"reference_vs_baseline.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Log baseline results\n",
    "logger.info(f\"Baseline evaluation complete. Score: {baseline_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    evaluator: TemplateFitnessEvaluator,\n",
    "    experiment_name: str,\n",
    "    llm_seeds: List[Dict[str, List[str]]],\n",
    "    results_array: List[Dict],\n",
    "    max_generations: int = MAX_GENERATIONS,\n",
    "    save_every: int = SAVE_EVERY_N_GENERATIONS,\n",
    "    is_adaptive: bool = False,\n",
    "    save_all_images: bool = SAVE_ALL_IMAGES\n",
    ") -> Tuple[Dict[str, Any], List[BlockGenome]]:\n",
    "    \"\"\"\n",
    "    Run one complete evolutionary experiment with comprehensive image saving.\n",
    "    \n",
    "    Args:\n",
    "        evaluator: Fitness evaluator (static or adaptive)\n",
    "        experiment_name: Name for saving results\n",
    "        llm_seeds: LLM-generated seed prompts for initialization\n",
    "        results_array: List to store all results (prompts, images, fitness)\n",
    "        max_generations: Maximum number of generations\n",
    "        save_every: Save checkpoint every N generations\n",
    "        is_adaptive: Whether using adaptive evaluator\n",
    "        save_all_images: Whether to save all generated images\n",
    "    \n",
    "    Returns:\n",
    "        history: Dict with fitness tracking per generation\n",
    "        final_population: Final evolved population\n",
    "    \"\"\"\n",
    "    # Create experiment output directory\n",
    "    exp_dir = OUTPUT_DIR / experiment_name\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create images directory for all images\n",
    "    images_dir = exp_dir / \"all_images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize tracking\n",
    "    history = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'worst_fitness': [],\n",
    "        'diversity': [],\n",
    "        'best_prompts': [],\n",
    "        'clip_weights': [],\n",
    "        'lpips_weights': [],\n",
    "        'block_diversity': []\n",
    "    }\n",
    "    \n",
    "    # Initialize population with LLM seeds\n",
    "    print(f\"Initializing population with LLM seeds...\")\n",
    "    population = engine.initialize_population(USER_SUBJECT, llm_seeds=llm_seeds)\n",
    "    print(f\"Population size: {len(population)}\")\n",
    "    \n",
    "    # Evolution loop\n",
    "    for generation in range(max_generations):\n",
    "        print(f\"\\n--- Generation {generation + 1}/{max_generations} ---\")\n",
    "        \n",
    "        # Update adaptive weights if using adaptive evaluator\n",
    "        if is_adaptive:\n",
    "            evaluator.update_generation(generation)\n",
    "            current_clip_weight = evaluator.clip_weight\n",
    "            current_lpips_weight = evaluator.lpips_weight\n",
    "        else:\n",
    "            current_clip_weight = STATIC_CLIP_WEIGHT\n",
    "            current_lpips_weight = STATIC_LPIPS_WEIGHT\n",
    "        \n",
    "        history['clip_weights'].append(current_clip_weight)\n",
    "        history['lpips_weights'].append(current_lpips_weight)\n",
    "        \n",
    "        print(f\"Weights: CLIP={current_clip_weight:.2f}, LPIPS={current_lpips_weight:.2f}\")\n",
    "        \n",
    "        # Evaluate fitness for all genomes\n",
    "        gen_images = []\n",
    "        for idx, genome in enumerate(tqdm(population, desc=\"Evaluating population\")):\n",
    "            try:\n",
    "                # Generate image with negative prompt support\n",
    "                image, metadata = model.generate(\n",
    "                    prompt=genome.to_prompt(),\n",
    "                    negative_prompt=genome.get_negative_prompt() or None,\n",
    "                    image_size=IMAGE_SIZE,\n",
    "                    num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "                    guidance_scale=GUIDANCE_SCALE,\n",
    "                    seed=GENERATION_SEED + generation * 100 + idx\n",
    "                )\n",
    "                \n",
    "                # Evaluate fitness (using subject for CLIP)\n",
    "                genome.fitness = evaluator.evaluate(image, USER_SUBJECT)\n",
    "                gen_images.append((genome.fitness, image, genome.to_prompt(), genome))\n",
    "                \n",
    "                # Save image with generation index and fitness score\n",
    "                if save_all_images:\n",
    "                    img_filename = f\"gen{generation+1:03d}_idx{idx:02d}_fit{genome.fitness:.4f}.jpg\"\n",
    "                    img_path = images_dir / img_filename\n",
    "                    image.save(img_path)\n",
    "                \n",
    "                # Add to results array\n",
    "                result_entry = {\n",
    "                    'experiment': experiment_name,\n",
    "                    'generation': generation + 1,\n",
    "                    'individual_index': idx,\n",
    "                    'prompt': genome.to_prompt(),\n",
    "                    'negative_prompt': genome.get_negative_prompt(),\n",
    "                    'blocks': {\n",
    "                        'composition': genome.composition.copy(),\n",
    "                        'lighting': genome.lighting.copy(),\n",
    "                        'style': genome.style.copy(),\n",
    "                        'quality': genome.quality.copy(),\n",
    "                        'negative': genome.negative.copy()\n",
    "                    },\n",
    "                    'fitness': float(genome.fitness),\n",
    "                    'image_path': str(img_path) if save_all_images else None,\n",
    "                    'clip_weight': current_clip_weight,\n",
    "                    'lpips_weight': current_lpips_weight\n",
    "                }\n",
    "                results_array.append(result_entry)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating genome {idx}: {e}\")\n",
    "                genome.fitness = 0.0\n",
    "        \n",
    "        # Track fitness statistics\n",
    "        fitnesses = [g.fitness for g in population]\n",
    "        best_fitness = max(fitnesses)\n",
    "        avg_fitness = np.mean(fitnesses)\n",
    "        worst_fitness = min(fitnesses)\n",
    "        \n",
    "        # Get block-wise diversity\n",
    "        diversity_dict = engine.get_diversity(population)\n",
    "        overall_diversity = np.mean(list(diversity_dict.values()))\n",
    "        \n",
    "        history['best_fitness'].append(best_fitness)\n",
    "        history['avg_fitness'].append(avg_fitness)\n",
    "        history['worst_fitness'].append(worst_fitness)\n",
    "        history['diversity'].append(overall_diversity)\n",
    "        history['block_diversity'].append(diversity_dict)\n",
    "        \n",
    "        # Get best genome\n",
    "        best_genome = engine.get_best(population)\n",
    "        history['best_prompts'].append(best_genome.to_prompt())\n",
    "        \n",
    "        print(f\"Best: {best_fitness:.4f} | Avg: {avg_fitness:.4f} | Diversity: {overall_diversity:.2f}\")\n",
    "        print(f\"Best prompt: {best_genome.to_prompt()[:80]}...\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (generation + 1) % save_every == 0 or generation == max_generations - 1:\n",
    "            checkpoint_dir = exp_dir / f\"gen_{generation + 1:02d}\"\n",
    "            checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Save best image\n",
    "            if gen_images:\n",
    "                gen_images.sort(key=lambda x: x[0], reverse=True)\n",
    "                best_img = gen_images[0][1]\n",
    "                best_img.save(checkpoint_dir / \"best_image.jpg\")\n",
    "            \n",
    "            # Save checkpoint data\n",
    "            checkpoint_data = {\n",
    "                'generation': generation + 1,\n",
    "                'best_fitness': best_fitness,\n",
    "                'avg_fitness': avg_fitness,\n",
    "                'best_prompt': best_genome.to_prompt(),\n",
    "                'best_negative': best_genome.get_negative_prompt(),\n",
    "                'blocks': {\n",
    "                    'composition': best_genome.composition,\n",
    "                    'lighting': best_genome.lighting,\n",
    "                    'style': best_genome.style,\n",
    "                    'quality': best_genome.quality,\n",
    "                    'negative': best_genome.negative\n",
    "                }\n",
    "            }\n",
    "            save_json(checkpoint_data, str(checkpoint_dir / \"checkpoint.json\"))\n",
    "            print(f\"Checkpoint saved to {checkpoint_dir}\")\n",
    "        \n",
    "        # Evolve to next generation (except on last generation)\n",
    "        if generation < max_generations - 1:\n",
    "            population = engine.evolve_generation(population)\n",
    "    \n",
    "    # Save final results\n",
    "    final_results = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'generations': max_generations,\n",
    "        'final_best_fitness': history['best_fitness'][-1],\n",
    "        'final_avg_fitness': history['avg_fitness'][-1],\n",
    "        'history': {\n",
    "            'best_fitness': history['best_fitness'],\n",
    "            'avg_fitness': history['avg_fitness'],\n",
    "            'worst_fitness': history['worst_fitness'],\n",
    "            'diversity': history['diversity'],\n",
    "            'clip_weights': history['clip_weights'],\n",
    "            'lpips_weights': history['lpips_weights']\n",
    "        }\n",
    "    }\n",
    "    save_json(final_results, str(exp_dir / \"final_results.json\"))\n",
    "    \n",
    "    logger.info(f\"{experiment_name} complete. Best fitness: {history['best_fitness'][-1]:.4f}\")\n",
    "    \n",
    "    return history, population\n",
    "\n",
    "\n",
    "def visualize_results(history: Dict[str, List], baseline_score: float, title: str = \"Evolution Progress\"):\n",
    "    \"\"\"\n",
    "    Create publication-quality convergence plot.\n",
    "    \"\"\"\n",
    "    generations = range(1, len(history['best_fitness']) + 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(generations, history['best_fitness'], 'g-', linewidth=2, \n",
    "            label='Best Fitness', marker='o', markersize=4)\n",
    "    ax.plot(generations, history['avg_fitness'], 'b--', linewidth=1.5,\n",
    "            label='Average Fitness', alpha=0.8)\n",
    "    ax.fill_between(generations, history['worst_fitness'], history['best_fitness'],\n",
    "                    alpha=0.2, color='green', label='Fitness Range')\n",
    "    \n",
    "    ax.axhline(y=baseline_score, color='orange', linestyle='-.', \n",
    "               linewidth=2, label=f'Baseline ({baseline_score:.4f})')\n",
    "    \n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Fitness Score')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(1, len(generations))\n",
    "    \n",
    "    y_min = min(min(history['worst_fitness']), baseline_score) * 0.95\n",
    "    y_max = max(history['best_fitness']) * 1.05\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compare_experiments(\n",
    "    exp1_history: Dict[str, List],\n",
    "    exp2_history: Dict[str, List],\n",
    "    baseline_score: float,\n",
    "    exp1_name: str = \"Static Weights\",\n",
    "    exp2_name: str = \"Adaptive Weights\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create side-by-side comparison plot for two experiments.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    generations = range(1, len(exp1_history['best_fitness']) + 1)\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(generations, exp1_history['best_fitness'], 'b-', linewidth=2,\n",
    "             label=f'{exp1_name} (Best)', marker='o', markersize=4)\n",
    "    ax1.plot(generations, exp2_history['best_fitness'], 'r-', linewidth=2,\n",
    "             label=f'{exp2_name} (Best)', marker='s', markersize=4)\n",
    "    ax1.axhline(y=baseline_score, color='orange', linestyle='-.', \n",
    "                linewidth=2, label=f'Baseline ({baseline_score:.4f})')\n",
    "    \n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Fitness Score')\n",
    "    ax1.set_title('Best Fitness Comparison')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(generations, exp1_history['clip_weights'], 'b--', linewidth=2,\n",
    "             label=f'{exp1_name} CLIP Weight')\n",
    "    ax2.plot(generations, exp2_history['clip_weights'], 'r-', linewidth=2,\n",
    "             label=f'{exp2_name} CLIP Weight')\n",
    "    ax2.plot(generations, exp2_history['lpips_weights'], 'r:', linewidth=2,\n",
    "             label=f'{exp2_name} LPIPS Weight')\n",
    "    \n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Weight Value')\n",
    "    ax2.set_title('Fitness Weight Evolution')\n",
    "    ax2.legend(loc='center right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def generate_final_image(genome: BlockGenome, seed: int = GENERATION_SEED) -> Tuple[Image.Image, float]:\n",
    "    \"\"\"\n",
    "    Generate final image for a genome with consistent seed.\n",
    "    \"\"\"\n",
    "    image, _ = model.generate(\n",
    "        prompt=genome.to_prompt(),\n",
    "        negative_prompt=genome.get_negative_prompt() or None,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        guidance_scale=GUIDANCE_SCALE,\n",
    "        seed=seed\n",
    "    )\n",
    "    fitness = static_evaluator.evaluate(image, USER_SUBJECT)\n",
    "    return image, fitness\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Run Experiment 2.1 (Static Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2.1: STATIC WEIGHTS\")\n",
    "print(f\"CLIP Weight: {STATIC_CLIP_WEIGHT} (fixed)\")\n",
    "print(f\"LPIPS Weight: {STATIC_LPIPS_WEIGHT} (fixed)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run experiment with static weights\n",
    "static_history, static_population = run_experiment(\n",
    "    evaluator=static_evaluator,\n",
    "    experiment_name=\"exp2_1_static\",\n",
    "    llm_seeds=llm_seeds,\n",
    "    results_array=ALL_RESULTS,\n",
    "    max_generations=MAX_GENERATIONS,\n",
    "    save_every=SAVE_EVERY_N_GENERATIONS,\n",
    "    is_adaptive=False\n",
    ")\n",
    "\n",
    "# Get best genome from static experiment\n",
    "best_static_genome = max(static_population, key=lambda g: g.fitness)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 2.1 RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final Best Fitness: {best_static_genome.fitness:.4f}\")\n",
    "print(f\"Improvement over baseline: {(best_static_genome.fitness - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "print(f\"\\nBest Prompt:\")\n",
    "print(f\"  {best_static_genome.to_prompt()}\")\n",
    "print(f\"\\nNegative Prompt:\")\n",
    "print(f\"  {best_static_genome.get_negative_prompt()}\")\n",
    "print(f\"\\nBlock Breakdown:\")\n",
    "print(f\"  Composition: {best_static_genome.composition}\")\n",
    "print(f\"  Lighting: {best_static_genome.lighting}\")\n",
    "print(f\"  Style: {best_static_genome.style}\")\n",
    "print(f\"  Quality: {best_static_genome.quality}\")\n",
    "print(f\"  Negative: {best_static_genome.negative}\")\n",
    "print(f\"\\nTotal images generated so far: {len(ALL_RESULTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize static experiment convergence\n",
    "fig_static = visualize_results(\n",
    "    static_history, \n",
    "    baseline_score,\n",
    "    title=\"Experiment 2.1: Static Weights Evolution\"\n",
    ")\n",
    "fig_static.savefig(OUTPUT_DIR / \"exp2_1_convergence.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Run Experiment 2.2 (Adaptive Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2.2: ADAPTIVE WEIGHTS\")\n",
    "print(f\"CLIP Weight: {INITIAL_CLIP_WEIGHT} -> {FINAL_CLIP_WEIGHT}\")\n",
    "print(f\"LPIPS Weight: {1-INITIAL_CLIP_WEIGHT} -> {1-FINAL_CLIP_WEIGHT}\")\n",
    "print(\"Strategy: Start structure-focused (LPIPS), end content-focused (CLIP)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Re-create adaptive evaluator to reset state\n",
    "adaptive_evaluator = AdaptiveTemplateFitnessEvaluator(\n",
    "    reference_image=reference_image,\n",
    "    initial_clip_weight=INITIAL_CLIP_WEIGHT,\n",
    "    final_clip_weight=FINAL_CLIP_WEIGHT,\n",
    "    max_generations=MAX_GENERATIONS\n",
    ")\n",
    "\n",
    "# Run experiment with adaptive weights\n",
    "adaptive_history, adaptive_population = run_experiment(\n",
    "    evaluator=adaptive_evaluator,\n",
    "    experiment_name=\"exp2_2_adaptive\",\n",
    "    llm_seeds=llm_seeds,\n",
    "    results_array=ALL_RESULTS,\n",
    "    max_generations=MAX_GENERATIONS,\n",
    "    save_every=SAVE_EVERY_N_GENERATIONS,\n",
    "    is_adaptive=True\n",
    ")\n",
    "\n",
    "# Get best genome from adaptive experiment\n",
    "best_adaptive_genome = max(adaptive_population, key=lambda g: g.fitness)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 2.2 RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final Best Fitness: {best_adaptive_genome.fitness:.4f}\")\n",
    "print(f\"Improvement over baseline: {(best_adaptive_genome.fitness - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "print(f\"\\nBest Prompt:\")\n",
    "print(f\"  {best_adaptive_genome.to_prompt()}\")\n",
    "print(f\"\\nNegative Prompt:\")\n",
    "print(f\"  {best_adaptive_genome.get_negative_prompt()}\")\n",
    "print(f\"\\nBlock Breakdown:\")\n",
    "print(f\"  Composition: {best_adaptive_genome.composition}\")\n",
    "print(f\"  Lighting: {best_adaptive_genome.lighting}\")\n",
    "print(f\"  Style: {best_adaptive_genome.style}\")\n",
    "print(f\"  Quality: {best_adaptive_genome.quality}\")\n",
    "print(f\"  Negative: {best_adaptive_genome.negative}\")\n",
    "print(f\"\\nTotal images generated: {len(ALL_RESULTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize adaptive experiment convergence\n",
    "fig_adaptive = visualize_results(\n",
    "    adaptive_history, \n",
    "    baseline_score,\n",
    "    title=\"Experiment 2.2: Adaptive Weights Evolution\"\n",
    ")\n",
    "fig_adaptive.savefig(OUTPUT_DIR / \"exp2_2_convergence.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Comparison & Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: STATIC vs ADAPTIVE WEIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Side-by-side convergence comparison\n",
    "fig_comparison = compare_experiments(\n",
    "    static_history,\n",
    "    adaptive_history,\n",
    "    baseline_score,\n",
    "    exp1_name=\"Static (2.1)\",\n",
    "    exp2_name=\"Adaptive (2.2)\"\n",
    ")\n",
    "fig_comparison.savefig(OUTPUT_DIR / \"comparison_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Extract final fitness values for statistical comparison\n",
    "static_final = [g.fitness for g in static_population]\n",
    "adaptive_final = [g.fitness for g in adaptive_population]\n",
    "\n",
    "# Statistical tests\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Independent samples t-test\n",
    "t_stat, p_value = stats.ttest_ind(static_final, adaptive_final)\n",
    "print(f\"\\nIndependent t-test:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Significant (p < 0.05): {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Mann-Whitney U test (non-parametric alternative)\n",
    "u_stat, u_pvalue = stats.mannwhitneyu(static_final, adaptive_final, alternative='two-sided')\n",
    "print(f\"\\nMann-Whitney U test:\")\n",
    "print(f\"  U-statistic: {u_stat:.4f}\")\n",
    "print(f\"  p-value: {u_pvalue:.4f}\")\n",
    "print(f\"  Significant (p < 0.05): {'Yes' if u_pvalue < 0.05 else 'No'}\")\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nBaseline:\")\n",
    "print(f\"  Fitness: {baseline_score:.4f}\")\n",
    "\n",
    "print(f\"\\nStatic Weights (Exp 2.1):\")\n",
    "print(f\"  Mean:   {np.mean(static_final):.4f}\")\n",
    "print(f\"  Std:    {np.std(static_final):.4f}\")\n",
    "print(f\"  Min:    {np.min(static_final):.4f}\")\n",
    "print(f\"  Max:    {np.max(static_final):.4f}\")\n",
    "print(f\"  Median: {np.median(static_final):.4f}\")\n",
    "\n",
    "print(f\"\\nAdaptive Weights (Exp 2.2):\")\n",
    "print(f\"  Mean:   {np.mean(adaptive_final):.4f}\")\n",
    "print(f\"  Std:    {np.std(adaptive_final):.4f}\")\n",
    "print(f\"  Min:    {np.min(adaptive_final):.4f}\")\n",
    "print(f\"  Max:    {np.max(adaptive_final):.4f}\")\n",
    "print(f\"  Median: {np.median(adaptive_final):.4f}\")\n",
    "\n",
    "# Effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(static_final) - 1) * np.var(static_final) + \n",
    "                      (len(adaptive_final) - 1) * np.var(adaptive_final)) / \n",
    "                     (len(static_final) + len(adaptive_final) - 2))\n",
    "cohens_d = (np.mean(adaptive_final) - np.mean(static_final)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "print(f\"\\nEffect Size (Cohen's d): {cohens_d:.4f}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_interpretation = \"negligible\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_interpretation = \"small\"\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    effect_interpretation = \"medium\"\n",
    "else:\n",
    "    effect_interpretation = \"large\"\n",
    "print(f\"  Interpretation: {effect_interpretation} effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "box_data = [static_final, adaptive_final]\n",
    "bp = ax.boxplot(box_data, labels=['Static Weights\\n(Exp 2.1)', 'Adaptive Weights\\n(Exp 2.2)'],\n",
    "                patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "\n",
    "# Add baseline line\n",
    "ax.axhline(y=baseline_score, color='orange', linestyle='--', \n",
    "           linewidth=2, label=f'Baseline ({baseline_score:.4f})')\n",
    "\n",
    "ax.set_ylabel('Fitness Score')\n",
    "ax.set_title('Final Population Fitness Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"boxplot_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating final comparison images...\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "# Generate final images with consistent seed for fair comparison\n",
    "COMPARISON_SEED = 12345\n",
    "\n",
    "# Baseline image (regenerate with comparison seed)\n",
    "print(\"Generating baseline image...\")\n",
    "baseline_final_image, baseline_final_score = generate_final_image(\n",
    "    factory.create_empty(USER_SUBJECT), \n",
    "    seed=COMPARISON_SEED\n",
    ")\n",
    "\n",
    "# Best static image\n",
    "print(\"Generating best static weights image...\")\n",
    "static_final_image, static_final_score = generate_final_image(\n",
    "    best_static_genome, \n",
    "    seed=COMPARISON_SEED\n",
    ")\n",
    "\n",
    "# Best adaptive image\n",
    "print(\"Generating best adaptive weights image...\")\n",
    "adaptive_final_image, adaptive_final_score = generate_final_image(\n",
    "    best_adaptive_genome, \n",
    "    seed=COMPARISON_SEED\n",
    ")\n",
    "\n",
    "print(\"Image generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visual comparison: Reference + Baseline + Static + Adaptive\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Reference\n",
    "axes[0].imshow(reference_image)\n",
    "axes[0].set_title(\"Reference Image\\n(Style Source)\", fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Baseline\n",
    "axes[1].imshow(baseline_final_image)\n",
    "axes[1].set_title(f\"Baseline\\nFitness: {baseline_final_score:.4f}\", fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Static best\n",
    "axes[2].imshow(static_final_image)\n",
    "improvement_static = (static_final_score - baseline_final_score) / baseline_final_score * 100\n",
    "axes[2].set_title(f\"Static Weights (2.1)\\nFitness: {static_final_score:.4f} (+{improvement_static:.1f}%)\", fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Adaptive best\n",
    "axes[3].imshow(adaptive_final_image)\n",
    "improvement_adaptive = (adaptive_final_score - baseline_final_score) / baseline_final_score * 100\n",
    "axes[3].set_title(f\"Adaptive Weights (2.2)\\nFitness: {adaptive_final_score:.4f} (+{improvement_adaptive:.1f}%)\", fontsize=12)\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Template Transfer: {USER_SUBJECT[:40]}...\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"visual_comparison.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save individual images\n",
    "baseline_final_image.save(OUTPUT_DIR / \"final_baseline.jpg\")\n",
    "static_final_image.save(OUTPUT_DIR / \"final_static_best.jpg\")\n",
    "adaptive_final_image.save(OUTPUT_DIR / \"final_adaptive_best.jpg\")\n",
    "\n",
    "print(\"\\nImages saved to output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evolved prompts for comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"EVOLVED PROMPTS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nBASELINE PROMPT:\")\n",
    "print(f\"  Positive: {USER_SUBJECT}\")\n",
    "print(f\"  Negative: (none)\")\n",
    "\n",
    "print(f\"\\nSTATIC WEIGHTS BEST PROMPT:\")\n",
    "print(f\"  Full: {best_static_genome.to_prompt()}\")\n",
    "print(f\"  Negative: {best_static_genome.get_negative_prompt()}\")\n",
    "print(f\"  Blocks:\")\n",
    "print(f\"    Composition: {best_static_genome.composition}\")\n",
    "print(f\"    Lighting: {best_static_genome.lighting}\")\n",
    "print(f\"    Style: {best_static_genome.style}\")\n",
    "print(f\"    Quality: {best_static_genome.quality}\")\n",
    "\n",
    "print(f\"\\nADAPTIVE WEIGHTS BEST PROMPT:\")\n",
    "print(f\"  Full: {best_adaptive_genome.to_prompt()}\")\n",
    "print(f\"  Negative: {best_adaptive_genome.get_negative_prompt()}\")\n",
    "print(f\"  Blocks:\")\n",
    "print(f\"    Composition: {best_adaptive_genome.composition}\")\n",
    "print(f\"    Lighting: {best_adaptive_genome.lighting}\")\n",
    "print(f\"    Style: {best_adaptive_genome.style}\")\n",
    "print(f\"    Quality: {best_adaptive_genome.quality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Export Results for IEEE Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results for IEEE paper\n",
    "print(\"Compiling results for IEEE paper export...\")\n",
    "\n",
    "# Convert numpy types to Python native types for JSON serialization\n",
    "def to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_native(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "# Prepare results dictionary\n",
    "results = {\n",
    "    \"metadata\": {\n",
    "        \"experiment\": \"2_template_transfer\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"reference_generated\": GENERATE_REFERENCE,\n",
    "        \"llm_seeding\": USE_LLM_SEEDING\n",
    "    },\n",
    "    \"configuration\": {\n",
    "        \"user_subject\": USER_SUBJECT,\n",
    "        \"reference_prompt\": REFERENCE_PROMPT if GENERATE_REFERENCE else None,\n",
    "        \"population_size\": POPULATION_SIZE,\n",
    "        \"max_generations\": MAX_GENERATIONS,\n",
    "        \"elite_size\": ELITE_SIZE,\n",
    "        \"mutation_rate\": MUTATION_RATE,\n",
    "        \"max_items_per_block\": MAX_ITEMS_PER_BLOCK\n",
    "    },\n",
    "    \"baseline\": {\n",
    "        \"prompt\": USER_SUBJECT,\n",
    "        \"fitness\": float(baseline_score)\n",
    "    },\n",
    "    \"static_weights\": {\n",
    "        \"clip_weight\": STATIC_CLIP_WEIGHT,\n",
    "        \"lpips_weight\": STATIC_LPIPS_WEIGHT,\n",
    "        \"final_best_fitness\": float(max(static_final)),\n",
    "        \"final_avg_fitness\": float(np.mean(static_final)),\n",
    "        \"final_std_fitness\": float(np.std(static_final)),\n",
    "        \"improvement_percent\": float((max(static_final) - baseline_score) / baseline_score * 100),\n",
    "        \"best_prompt\": best_static_genome.to_prompt(),\n",
    "        \"best_negative\": best_static_genome.get_negative_prompt(),\n",
    "        \"best_blocks\": {\n",
    "            \"composition\": best_static_genome.composition,\n",
    "            \"lighting\": best_static_genome.lighting,\n",
    "            \"style\": best_static_genome.style,\n",
    "            \"quality\": best_static_genome.quality,\n",
    "            \"negative\": best_static_genome.negative\n",
    "        },\n",
    "        \"convergence_history\": to_native({\n",
    "            'best_fitness': static_history['best_fitness'],\n",
    "            'avg_fitness': static_history['avg_fitness'],\n",
    "            'diversity': static_history['diversity']\n",
    "        })\n",
    "    },\n",
    "    \"adaptive_weights\": {\n",
    "        \"initial_clip_weight\": INITIAL_CLIP_WEIGHT,\n",
    "        \"final_clip_weight\": FINAL_CLIP_WEIGHT,\n",
    "        \"final_best_fitness\": float(max(adaptive_final)),\n",
    "        \"final_avg_fitness\": float(np.mean(adaptive_final)),\n",
    "        \"final_std_fitness\": float(np.std(adaptive_final)),\n",
    "        \"improvement_percent\": float((max(adaptive_final) - baseline_score) / baseline_score * 100),\n",
    "        \"best_prompt\": best_adaptive_genome.to_prompt(),\n",
    "        \"best_negative\": best_adaptive_genome.get_negative_prompt(),\n",
    "        \"best_blocks\": {\n",
    "            \"composition\": best_adaptive_genome.composition,\n",
    "            \"lighting\": best_adaptive_genome.lighting,\n",
    "            \"style\": best_adaptive_genome.style,\n",
    "            \"quality\": best_adaptive_genome.quality,\n",
    "            \"negative\": best_adaptive_genome.negative\n",
    "        },\n",
    "        \"convergence_history\": to_native({\n",
    "            'best_fitness': adaptive_history['best_fitness'],\n",
    "            'avg_fitness': adaptive_history['avg_fitness'],\n",
    "            'diversity': adaptive_history['diversity']\n",
    "        })\n",
    "    },\n",
    "    \"statistical_tests\": {\n",
    "        \"t_test\": {\n",
    "            \"t_statistic\": float(t_stat),\n",
    "            \"p_value\": float(p_value),\n",
    "            \"significant\": bool(p_value < 0.05)\n",
    "        },\n",
    "        \"mann_whitney_u\": {\n",
    "            \"u_statistic\": float(u_stat),\n",
    "            \"p_value\": float(u_pvalue),\n",
    "            \"significant\": bool(u_pvalue < 0.05)\n",
    "        },\n",
    "        \"effect_size\": {\n",
    "            \"cohens_d\": float(cohens_d),\n",
    "            \"interpretation\": effect_interpretation\n",
    "        }\n",
    "    },\n",
    "    \"comparison_summary\": {\n",
    "        \"winner\": \"adaptive\" if np.mean(adaptive_final) > np.mean(static_final) else \"static\",\n",
    "        \"static_mean\": float(np.mean(static_final)),\n",
    "        \"adaptive_mean\": float(np.mean(adaptive_final)),\n",
    "        \"difference\": float(np.mean(adaptive_final) - np.mean(static_final)),\n",
    "        \"relative_improvement\": float((np.mean(adaptive_final) - np.mean(static_final)) / np.mean(static_final) * 100) if np.mean(static_final) > 0 else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_path = OUTPUT_DIR / \"results_experiment_2.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "# Print summary for paper\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY FOR IEEE PAPER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. BASELINE PERFORMANCE\")\n",
    "print(f\"   - Fitness: {baseline_score:.4f}\")\n",
    "\n",
    "print(f\"\\n2. EXPERIMENT 2.1 (STATIC WEIGHTS)\")\n",
    "print(f\"   - Best Fitness: {max(static_final):.4f}\")\n",
    "print(f\"   - Mean Fitness: {np.mean(static_final):.4f} (+/- {np.std(static_final):.4f})\")\n",
    "print(f\"   - Improvement: +{(max(static_final) - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n3. EXPERIMENT 2.2 (ADAPTIVE WEIGHTS)\")\n",
    "print(f\"   - Best Fitness: {max(adaptive_final):.4f}\")\n",
    "print(f\"   - Mean Fitness: {np.mean(adaptive_final):.4f} (+/- {np.std(adaptive_final):.4f})\")\n",
    "print(f\"   - Improvement: +{(max(adaptive_final) - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n4. STATISTICAL SIGNIFICANCE\")\n",
    "print(f\"   - t-test p-value: {p_value:.4f} ({'significant' if p_value < 0.05 else 'not significant'})\")\n",
    "print(f\"   - Cohen's d: {cohens_d:.4f} ({effect_interpretation} effect)\")\n",
    "\n",
    "winner = \"Adaptive\" if np.mean(adaptive_final) > np.mean(static_final) else \"Static\"\n",
    "print(f\"\\n5. CONCLUSION\")\n",
    "print(f\"   - Better approach: {winner} Weights\")\n",
    "print(f\"   - Difference in mean fitness: {abs(np.mean(adaptive_final) - np.mean(static_final)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table for paper\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LaTeX TABLE FOR IEEE PAPER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "latex_table = r\"\"\"\n",
    "\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Experiment 2: Template Transfer Results}\n",
    "\\label{tab:exp2_results}\n",
    "\\begin{tabular}{lccc}\n",
    "\\hline\n",
    "\\textbf{Metric} & \\textbf{Baseline} & \\textbf{Static} & \\textbf{Adaptive} \\\\\n",
    "\\hline\n",
    "Best Fitness & %.4f & %.4f & %.4f \\\\\n",
    "Mean Fitness & - & %.4f & %.4f \\\\\n",
    "Std Dev & - & %.4f & %.4f \\\\\n",
    "Improvement (\\%%) & - & +%.2f\\%% & +%.2f\\%% \\\\\n",
    "\\hline\n",
    "\\multicolumn{4}{l}{\\textit{Fitness: %.1f\\%% CLIP + %.1f\\%% LPIPS (Static)}} \\\\\n",
    "\\multicolumn{4}{l}{\\textit{Fitness: %.1f\\%% $\\rightarrow$ %.1f\\%% CLIP (Adaptive)}} \\\\\n",
    "\\multicolumn{4}{l}{\\textit{Statistical Test: t=%.4f, p=%.4f}} \\\\\n",
    "\\multicolumn{4}{l}{\\textit{Effect Size: Cohen's d=%.4f (%s)}} \\\\\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\" % (\n",
    "    baseline_score, max(static_final), max(adaptive_final),\n",
    "    np.mean(static_final), np.mean(adaptive_final),\n",
    "    np.std(static_final), np.std(adaptive_final),\n",
    "    (max(static_final) - baseline_score) / baseline_score * 100,\n",
    "    (max(adaptive_final) - baseline_score) / baseline_score * 100,\n",
    "    STATIC_CLIP_WEIGHT * 100, STATIC_LPIPS_WEIGHT * 100,\n",
    "    INITIAL_CLIP_WEIGHT * 100, FINAL_CLIP_WEIGHT * 100,\n",
    "    t_stat, p_value, cohens_d, effect_interpretation\n",
    ")\n",
    "\n",
    "print(latex_table)\n",
    "\n",
    "# Save LaTeX table\n",
    "with open(OUTPUT_DIR / \"table_experiment_2.tex\", 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"\\nLaTeX table saved to: {OUTPUT_DIR / 'table_experiment_2.tex'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 2 COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nOutput files saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for f in sorted(OUTPUT_DIR.glob(\"*\")):\n",
    "    if f.is_file():\n",
    "        print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nExperiment subdirectories:\")\n",
    "for d in sorted(OUTPUT_DIR.glob(\"exp*\")):\n",
    "    if d.is_dir():\n",
    "        print(f\"  - {d.name}/\")\n",
    "\n",
    "logger.info(\"Experiment 2 completed successfully.\")\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Return All Results Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ALL RESULTS ARRAY\n",
    "# =============================================================================\n",
    "# This cell returns the complete results array with all generated images,\n",
    "# prompts, and fitness scores.\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ALL RESULTS ARRAY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal entries in ALL_RESULTS: {len(ALL_RESULTS)}\")\n",
    "\n",
    "# Save ALL_RESULTS to JSON file\n",
    "all_results_path = OUTPUT_DIR / \"all_results_array.json\"\n",
    "save_json(ALL_RESULTS, str(all_results_path))\n",
    "print(f\"All results saved to: {all_results_path}\")\n",
    "\n",
    "# Display summary statistics\n",
    "exp2_1_results = [r for r in ALL_RESULTS if r['experiment'] == 'exp2_1_static']\n",
    "exp2_2_results = [r for r in ALL_RESULTS if r['experiment'] == 'exp2_2_adaptive']\n",
    "\n",
    "print(f\"\\nExperiment 2.1 (Static): {len(exp2_1_results)} images\")\n",
    "print(f\"Experiment 2.2 (Adaptive): {len(exp2_2_results)} images\")\n",
    "\n",
    "# Get top 10 results by fitness across all experiments\n",
    "sorted_results = sorted(ALL_RESULTS, key=lambda x: x['fitness'], reverse=True)\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"TOP 10 RESULTS BY FITNESS:\")\n",
    "print(\"-\" * 60)\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    print(f\"\\n{i}. Fitness: {result['fitness']:.4f}\")\n",
    "    print(f\"   Experiment: {result['experiment']}\")\n",
    "    print(f\"   Generation: {result['generation']}\")\n",
    "    print(f\"   Prompt: {result['prompt'][:80]}...\")\n",
    "    print(f\"   Negative: {result['negative_prompt'][:50] if result['negative_prompt'] else 'None'}...\")\n",
    "    print(f\"   Image: {result['image_path'].split('/')[-1] if result['image_path'] else 'N/A'}\")\n",
    "\n",
    "# Display the array structure\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"ARRAY STRUCTURE (sample entry):\")\n",
    "print(\"-\" * 60)\n",
    "if ALL_RESULTS:\n",
    "    sample = ALL_RESULTS[0]\n",
    "    for key, value in sample.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"  {key}:\")\n",
    "            for k, v in value.items():\n",
    "                print(f\"    {k}: {v[:3]}...\" if isinstance(v, list) and len(v) > 3 else f\"    {k}: {v}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"  {key}: {value[:3]}...\" if len(value) > 3 else f\"  {key}: {value}\")\n",
    "        elif isinstance(value, str) and len(value) > 50:\n",
    "            print(f\"  {key}: {value[:50]}...\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ACCESS ALL_RESULTS VARIABLE FOR FULL DATA\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return ALL_RESULTS array for programmatic access\n",
    "# This cell outputs the complete array containing all experimental data\n",
    "\n",
    "ALL_RESULTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
