{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Prompt Enhancement with Genetic Algorithms\n",
    "\n",
    "## Goal\n",
    "Evolve a basic prompt into an enhanced prompt using genetic algorithms.\n",
    "\n",
    "## Methodology\n",
    "- **Genome**: PromptGenome (base_prompt + positive_modifiers + negative_modifiers)\n",
    "- **Fitness**: w1 * CLIP_score + w2 * Aesthetic_score\n",
    "- **Model**: flux-schnell (Fal AI)\n",
    "\n",
    "## Sub-experiments\n",
    "- **1.1 Static Weights**: Fixed CLIP=0.6, Aesthetic=0.4 throughout evolution\n",
    "- **1.2 Adaptive Weights**: CLIP weight decreases from 0.8 â†’ 0.4 over generations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "# Add parent directory to path for src imports\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Project imports\n",
    "from src.genome import PromptGenome, GenomeFactory\n",
    "from src.evolution import GeneticOperators, EvolutionEngine\n",
    "from src.fitness import FitnessEvaluator, AdaptiveFitnessEvaluator\n",
    "from src.models import get_model\n",
    "from src.utils import (\n",
    "    create_modifier_vocab, \n",
    "    create_negative_vocab, \n",
    "    save_json,\n",
    "    Logger\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Configure matplotlib for publication-quality plots\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'legend.fontsize': 11,\n",
    "    'figure.figsize': (10, 6),\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight'\n",
    "})\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Environment setup complete.\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT PARAMETERS (ENHANCED)\n",
    "# =============================================================================\n",
    "\n",
    "# Base prompt to evolve\n",
    "BASE_PROMPT = \"a tiger in the jungle\"\n",
    "\n",
    "# Evolution parameters - INCREASED for better results\n",
    "POPULATION_SIZE = 20\n",
    "MAX_GENERATIONS = 100\n",
    "ELITE_SIZE = 2\n",
    "MUTATION_RATE = 0.5\n",
    "ADD_PROBABILITY = 0.35\n",
    "REMOVE_PROBABILITY = 0.2\n",
    "\n",
    "# Genome constraints - EXPANDED search space\n",
    "MAX_POSITIVE_MODIFIERS = 12\n",
    "MAX_NEGATIVE_MODIFIERS = 6\n",
    "\n",
    "# =============================================================================\n",
    "# FITNESS WEIGHTS\n",
    "# =============================================================================\n",
    "\n",
    "# Static weights (Experiment 1.1)\n",
    "STATIC_CLIP_WEIGHT = 0.6\n",
    "STATIC_AESTHETIC_WEIGHT = 0.4\n",
    "\n",
    "# Adaptive weights (Experiment 1.2)\n",
    "# Strategy: Start with semantic alignment, shift to aesthetic focus\n",
    "INITIAL_CLIP_WEIGHT = 0.8  # Early: prioritize CLIP (semantic alignment)\n",
    "FINAL_CLIP_WEIGHT = 0.4    # Late: prioritize aesthetics\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_NAME = \"flux-schnell\"\n",
    "IMAGE_SIZE = \"landscape_4_3\"\n",
    "NUM_INFERENCE_STEPS = 4\n",
    "GENERATION_SEED = 42  # Fixed seed for reproducible image generation\n",
    "\n",
    "# =============================================================================\n",
    "# OUTPUT SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_DIR = Path(\"../data/results/experiment_1\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_EVERY_N_GENERATIONS = 5  # Save checkpoints every N generations\n",
    "SAVE_ALL_IMAGES = True  # NEW: Save all generated images\n",
    "\n",
    "# =============================================================================\n",
    "# RESULTS TRACKING\n",
    "# =============================================================================\n",
    "\n",
    "# Global array to store all results\n",
    "ALL_RESULTS = []\n",
    "\n",
    "# Print configuration summary\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1 CONFIGURATION (ENHANCED)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBase Prompt: {BASE_PROMPT}\")\n",
    "print(f\"\\nEvolution Parameters:\")\n",
    "print(f\"  Population Size: {POPULATION_SIZE}\")\n",
    "print(f\"  Max Generations: {MAX_GENERATIONS}\")\n",
    "print(f\"  Elite Size: {ELITE_SIZE}\")\n",
    "print(f\"  Mutation Rate: {MUTATION_RATE}\")\n",
    "print(f\"  Max Positive Modifiers: {MAX_POSITIVE_MODIFIERS}\")\n",
    "print(f\"  Max Negative Modifiers: {MAX_NEGATIVE_MODIFIERS}\")\n",
    "print(f\"\\nStatic Weights (Exp 1.1):\")\n",
    "print(f\"  CLIP: {STATIC_CLIP_WEIGHT}, Aesthetic: {STATIC_AESTHETIC_WEIGHT}\")\n",
    "print(f\"\\nAdaptive Weights (Exp 1.2):\")\n",
    "print(f\"  CLIP: {INITIAL_CLIP_WEIGHT} -> {FINAL_CLIP_WEIGHT}\")\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"Save All Images: {SAVE_ALL_IMAGES}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE MODEL\n",
    "# =============================================================================\n",
    "print(\"Initializing image generation model...\")\n",
    "model = get_model(MODEL_NAME)\n",
    "print(f\"  Model: {MODEL_NAME} initialized\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE VOCABULARIES\n",
    "# =============================================================================\n",
    "print(\"\\nCreating vocabularies...\")\n",
    "modifier_vocab = create_modifier_vocab()\n",
    "negative_vocab = create_negative_vocab()\n",
    "print(f\"  Positive modifiers: {len(modifier_vocab)} terms\")\n",
    "print(f\"  Negative modifiers: {len(negative_vocab)} terms\")\n",
    "\n",
    "# Preview some modifiers\n",
    "print(f\"\\n  Sample positive modifiers: {modifier_vocab[:5]}\")\n",
    "print(f\"  Sample negative modifiers: {negative_vocab[:5]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE GENOME FACTORY\n",
    "# =============================================================================\n",
    "print(\"\\nCreating genome factory...\")\n",
    "factory = GenomeFactory(\n",
    "    modifier_vocab=modifier_vocab,\n",
    "    negative_vocab=negative_vocab,\n",
    "    max_positive_modifiers=MAX_POSITIVE_MODIFIERS,\n",
    "    max_negative_modifiers=MAX_NEGATIVE_MODIFIERS\n",
    ")\n",
    "print(f\"  Max positive modifiers: {MAX_POSITIVE_MODIFIERS}\")\n",
    "print(f\"  Max negative modifiers: {MAX_NEGATIVE_MODIFIERS}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE GENETIC OPERATORS\n",
    "# =============================================================================\n",
    "print(\"\\nCreating genetic operators...\")\n",
    "operators = GeneticOperators(\n",
    "    factory=factory,\n",
    "    mutation_rate=MUTATION_RATE,\n",
    "    add_probability=ADD_PROBABILITY,\n",
    "    remove_probability=REMOVE_PROBABILITY\n",
    ")\n",
    "print(f\"  Mutation rate: {MUTATION_RATE}\")\n",
    "print(f\"  Add probability: {ADD_PROBABILITY}\")\n",
    "print(f\"  Remove probability: {REMOVE_PROBABILITY}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE EVOLUTION ENGINE\n",
    "# =============================================================================\n",
    "print(\"\\nCreating evolution engine...\")\n",
    "engine = EvolutionEngine(\n",
    "    factory=factory,\n",
    "    operators=operators,\n",
    "    population_size=POPULATION_SIZE,\n",
    "    elite_size=ELITE_SIZE,\n",
    "    selection_method=\"tournament\"\n",
    ")\n",
    "print(f\"  Population size: {POPULATION_SIZE}\")\n",
    "print(f\"  Elite size: {ELITE_SIZE}\")\n",
    "print(f\"  Selection method: tournament\")\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE FITNESS EVALUATORS\n",
    "# =============================================================================\n",
    "print(\"\\nCreating fitness evaluators...\")\n",
    "\n",
    "# Static fitness evaluator (Experiment 1.1)\n",
    "static_evaluator = FitnessEvaluator(\n",
    "    clip_weight=STATIC_CLIP_WEIGHT,\n",
    "    aesthetic_weight=STATIC_AESTHETIC_WEIGHT\n",
    ")\n",
    "print(f\"  Static Evaluator: CLIP={STATIC_CLIP_WEIGHT}, Aesthetic={STATIC_AESTHETIC_WEIGHT}\")\n",
    "\n",
    "# Adaptive fitness evaluator (Experiment 1.2)\n",
    "adaptive_evaluator = AdaptiveFitnessEvaluator(\n",
    "    initial_clip_weight=INITIAL_CLIP_WEIGHT,\n",
    "    final_clip_weight=FINAL_CLIP_WEIGHT,\n",
    "    max_generations=MAX_GENERATIONS\n",
    ")\n",
    "print(f\"  Adaptive Evaluator: CLIP {INITIAL_CLIP_WEIGHT} -> {FINAL_CLIP_WEIGHT}\")\n",
    "\n",
    "# =============================================================================\n",
    "# INITIALIZE LOGGER\n",
    "# =============================================================================\n",
    "logger = Logger(log_dir=str(OUTPUT_DIR / \"logs\"), name=\"experiment_1\")\n",
    "logger.info(\"Experiment 1 components initialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL COMPONENTS INITIALIZED SUCCESSFULLY\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATE AND EVALUATE BASELINE\n",
    "# =============================================================================\n",
    "print(\"Generating baseline image (no modifiers)...\")\n",
    "print(f\"Prompt: {BASE_PROMPT}\")\n",
    "print()\n",
    "\n",
    "# Create baseline genome (empty modifiers)\n",
    "baseline_genome = factory.create_empty(BASE_PROMPT)\n",
    "print(f\"Baseline genome: {baseline_genome}\")\n",
    "\n",
    "# Generate baseline image\n",
    "try:\n",
    "    baseline_image, baseline_metadata = model.generate(\n",
    "        prompt=baseline_genome.to_prompt(),\n",
    "        image_size=IMAGE_SIZE,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        seed=GENERATION_SEED\n",
    "    )\n",
    "    print(\"Baseline image generated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating baseline image: {e}\")\n",
    "    raise\n",
    "\n",
    "# Evaluate baseline fitness using static evaluator\n",
    "print(\"\\nEvaluating baseline fitness...\")\n",
    "baseline_score = static_evaluator.evaluate(\n",
    "    image=baseline_image, \n",
    "    text=BASE_PROMPT, \n",
    "    verbose=True\n",
    ")\n",
    "print(f\"\\nBaseline Fitness Score: {baseline_score:.4f}\")\n",
    "\n",
    "# Save baseline image\n",
    "baseline_path = OUTPUT_DIR / \"baseline_image.jpg\"\n",
    "baseline_image.save(baseline_path)\n",
    "print(f\"Baseline image saved to: {baseline_path}\")\n",
    "\n",
    "# Display baseline image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(baseline_image)\n",
    "ax.set_title(f\"Baseline Image\\nPrompt: {BASE_PROMPT}\\nFitness: {baseline_score:.4f}\", fontsize=12)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"baseline_display.png\")\n",
    "plt.show()\n",
    "\n",
    "# Log baseline results\n",
    "logger.info(f\"Baseline evaluation complete. Score: {baseline_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert numpy types to native Python types\n",
    "def to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64, np.integer)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_native(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    evaluator: FitnessEvaluator,\n",
    "    experiment_name: str,\n",
    "    results_array: List[Dict],\n",
    "    max_generations: int = MAX_GENERATIONS,\n",
    "    save_every: int = SAVE_EVERY_N_GENERATIONS,\n",
    "    is_adaptive: bool = False,\n",
    "    save_all_images: bool = SAVE_ALL_IMAGES\n",
    ") -> Tuple[Dict[str, Any], List[PromptGenome]]:\n",
    "    \"\"\"\n",
    "    Run one complete evolutionary experiment with comprehensive image saving.\n",
    "    \n",
    "    Args:\n",
    "        evaluator: Fitness evaluator (static or adaptive)\n",
    "        experiment_name: Name for saving results\n",
    "        results_array: List to store all results (prompts, images, fitness)\n",
    "        max_generations: Maximum number of generations\n",
    "        save_every: Save checkpoint every N generations\n",
    "        is_adaptive: Whether using adaptive evaluator\n",
    "        save_all_images: Whether to save all generated images\n",
    "    \n",
    "    Returns:\n",
    "        history: Dict with fitness tracking per generation\n",
    "        final_population: Final evolved population\n",
    "    \"\"\"\n",
    "    # Create experiment output directory\n",
    "    exp_dir = OUTPUT_DIR / experiment_name\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create images directory for all images\n",
    "    images_dir = exp_dir / \"all_images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize tracking\n",
    "    history = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'worst_fitness': [],\n",
    "        'diversity': [],\n",
    "        'best_prompts': [],\n",
    "        'clip_weights': [],\n",
    "        'aesthetic_weights': []\n",
    "    }\n",
    "    \n",
    "    # Initialize population\n",
    "    print(f\"Initializing population of {POPULATION_SIZE} genomes...\")\n",
    "    population = engine.initialize_population(BASE_PROMPT)\n",
    "    \n",
    "    # Evolution loop\n",
    "    for generation in range(max_generations):\n",
    "        print(f\"\\n--- Generation {generation + 1}/{max_generations} ---\")\n",
    "        \n",
    "        # Update adaptive weights if using adaptive evaluator\n",
    "        if is_adaptive:\n",
    "            evaluator.update_generation(generation)\n",
    "            current_clip_weight = evaluator.clip_weight\n",
    "            current_aesthetic_weight = evaluator.aesthetic_weight\n",
    "        else:\n",
    "            current_clip_weight = STATIC_CLIP_WEIGHT\n",
    "            current_aesthetic_weight = STATIC_AESTHETIC_WEIGHT\n",
    "        \n",
    "        history['clip_weights'].append(float(current_clip_weight))\n",
    "        history['aesthetic_weights'].append(float(current_aesthetic_weight))\n",
    "        \n",
    "        print(f\"Weights: CLIP={current_clip_weight:.2f}, Aesthetic={current_aesthetic_weight:.2f}\")\n",
    "        \n",
    "        # Evaluate fitness for all genomes\n",
    "        gen_images = []\n",
    "        for idx, genome in enumerate(tqdm(population, desc=\"Evaluating population\")):\n",
    "            try:\n",
    "                # Generate image\n",
    "                image, metadata = model.generate(\n",
    "                    prompt=genome.to_prompt(),\n",
    "                    image_size=IMAGE_SIZE,\n",
    "                    num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "                    seed=GENERATION_SEED + generation * 100 + idx\n",
    "                )\n",
    "                \n",
    "                # Evaluate fitness\n",
    "                genome.fitness = evaluator.evaluate(image, BASE_PROMPT)\n",
    "                gen_images.append((genome.fitness, image, genome.to_prompt(), genome))\n",
    "                \n",
    "                # Save image with generation index and fitness score\n",
    "                if save_all_images:\n",
    "                    img_filename = f\"gen{generation+1:03d}_idx{idx:02d}_fit{float(genome.fitness):.4f}.jpg\"\n",
    "                    img_path = images_dir / img_filename\n",
    "                    image.save(img_path)\n",
    "                \n",
    "                # Add to results array\n",
    "                result_entry = {\n",
    "                    'experiment': experiment_name,\n",
    "                    'generation': generation + 1,\n",
    "                    'individual_index': idx,\n",
    "                    'prompt': genome.to_prompt(),\n",
    "                    'negative_prompt': genome.get_negative_prompt(),\n",
    "                    'positive_modifiers': genome.positive_modifiers.copy(),\n",
    "                    'negative_modifiers': genome.negative_modifiers.copy(),\n",
    "                    'fitness': float(genome.fitness),\n",
    "                    'image_path': str(img_path) if save_all_images else None,\n",
    "                    'clip_weight': float(current_clip_weight),\n",
    "                    'aesthetic_weight': float(current_aesthetic_weight)\n",
    "                }\n",
    "                results_array.append(result_entry)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating genome {idx}: {e}\")\n",
    "                genome.fitness = 0.0\n",
    "        \n",
    "        # Track fitness statistics\n",
    "        fitnesses = [g.fitness for g in population]\n",
    "        best_fitness = float(max(fitnesses))\n",
    "        avg_fitness = float(np.mean(fitnesses))\n",
    "        worst_fitness = float(min(fitnesses))\n",
    "        diversity = float(engine.get_diversity(population))\n",
    "        \n",
    "        history['best_fitness'].append(best_fitness)\n",
    "        history['avg_fitness'].append(avg_fitness)\n",
    "        history['worst_fitness'].append(worst_fitness)\n",
    "        history['diversity'].append(diversity)\n",
    "        \n",
    "        # Get best genome\n",
    "        best_genome = engine.get_best(population)\n",
    "        history['best_prompts'].append(best_genome.to_prompt())\n",
    "        \n",
    "        print(f\"Best: {best_fitness:.4f} | Avg: {avg_fitness:.4f} | Diversity: {diversity:.2f}\")\n",
    "        print(f\"Best prompt: {best_genome.to_prompt()[:80]}...\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (generation + 1) % save_every == 0 or generation == max_generations - 1:\n",
    "            checkpoint_dir = exp_dir / f\"gen_{generation + 1:02d}\"\n",
    "            checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Save best image\n",
    "            if gen_images:\n",
    "                gen_images.sort(key=lambda x: x[0], reverse=True)\n",
    "                best_img = gen_images[0][1]\n",
    "                best_img.save(checkpoint_dir / \"best_image.jpg\")\n",
    "            \n",
    "            # Save checkpoint data (convert to native types)\n",
    "            checkpoint_data = {\n",
    "                'generation': generation + 1,\n",
    "                'best_fitness': best_fitness,\n",
    "                'avg_fitness': avg_fitness,\n",
    "                'best_prompt': best_genome.to_prompt(),\n",
    "                'best_modifiers': best_genome.positive_modifiers,\n",
    "                'best_negative': best_genome.negative_modifiers\n",
    "            }\n",
    "            save_json(to_native(checkpoint_data), str(checkpoint_dir / \"checkpoint.json\"))\n",
    "            print(f\"Checkpoint saved to {checkpoint_dir}\")\n",
    "        \n",
    "        # Evolve to next generation (except on last generation)\n",
    "        if generation < max_generations - 1:\n",
    "            population = engine.evolve_generation(population)\n",
    "    \n",
    "    # Save final results (convert to native types)\n",
    "    final_results = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'generations': max_generations,\n",
    "        'final_best_fitness': history['best_fitness'][-1],\n",
    "        'final_avg_fitness': history['avg_fitness'][-1],\n",
    "        'history': to_native(history)\n",
    "    }\n",
    "    save_json(final_results, str(exp_dir / \"final_results.json\"))\n",
    "    \n",
    "    logger.info(f\"{experiment_name} complete. Best fitness: {history['best_fitness'][-1]:.4f}\")\n",
    "    \n",
    "    return history, population\n",
    "\n",
    "\n",
    "def visualize_results(history: Dict[str, List], baseline_score: float, title: str = \"Evolution Progress\"):\n",
    "    \"\"\"\n",
    "    Create publication-quality convergence plot.\n",
    "    \"\"\"\n",
    "    generations = range(1, len(history['best_fitness']) + 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(generations, history['best_fitness'], 'g-', linewidth=2, \n",
    "            label='Best Fitness', marker='o', markersize=4)\n",
    "    ax.plot(generations, history['avg_fitness'], 'b--', linewidth=1.5,\n",
    "            label='Average Fitness', alpha=0.8)\n",
    "    ax.fill_between(generations, history['worst_fitness'], history['best_fitness'],\n",
    "                    alpha=0.2, color='green', label='Fitness Range')\n",
    "    \n",
    "    ax.axhline(y=baseline_score, color='orange', linestyle='-.', \n",
    "               linewidth=2, label=f'Baseline ({baseline_score:.4f})')\n",
    "    \n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Fitness Score')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(1, len(generations))\n",
    "    \n",
    "    y_min = min(min(history['worst_fitness']), baseline_score) * 0.95\n",
    "    y_max = max(history['best_fitness']) * 1.05\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compare_experiments(\n",
    "    exp1_history: Dict[str, List],\n",
    "    exp2_history: Dict[str, List],\n",
    "    baseline_score: float,\n",
    "    exp1_name: str = \"Static Weights\",\n",
    "    exp2_name: str = \"Adaptive Weights\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create side-by-side comparison plot for two experiments.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    generations = range(1, len(exp1_history['best_fitness']) + 1)\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(generations, exp1_history['best_fitness'], 'b-', linewidth=2,\n",
    "             label=f'{exp1_name} (Best)', marker='o', markersize=4)\n",
    "    ax1.plot(generations, exp2_history['best_fitness'], 'r-', linewidth=2,\n",
    "             label=f'{exp2_name} (Best)', marker='s', markersize=4)\n",
    "    ax1.axhline(y=baseline_score, color='orange', linestyle='-.', \n",
    "                linewidth=2, label=f'Baseline ({baseline_score:.4f})')\n",
    "    \n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Fitness Score')\n",
    "    ax1.set_title('Best Fitness Comparison')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(generations, exp1_history['clip_weights'], 'b--', linewidth=2,\n",
    "             label=f'{exp1_name} CLIP Weight')\n",
    "    ax2.plot(generations, exp2_history['clip_weights'], 'r-', linewidth=2,\n",
    "             label=f'{exp2_name} CLIP Weight')\n",
    "    ax2.plot(generations, exp2_history['aesthetic_weights'], 'r:', linewidth=2,\n",
    "             label=f'{exp2_name} Aesthetic Weight')\n",
    "    \n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Weight Value')\n",
    "    ax2.set_title('Fitness Weight Evolution')\n",
    "    ax2.legend(loc='center right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def generate_final_image(genome: PromptGenome, seed: int = GENERATION_SEED) -> Tuple[Image.Image, float]:\n",
    "    \"\"\"\n",
    "    Generate final image for a genome with consistent seed.\n",
    "    \"\"\"\n",
    "    image, _ = model.generate(\n",
    "        prompt=genome.to_prompt(),\n",
    "        image_size=IMAGE_SIZE,\n",
    "        num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "        seed=seed\n",
    "    )\n",
    "    fitness = static_evaluator.evaluate(image, BASE_PROMPT)\n",
    "    return image, float(fitness)\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Run Experiment 1.1 (Static Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1.1: STATIC WEIGHTS\")\n",
    "print(f\"CLIP Weight: {STATIC_CLIP_WEIGHT} (fixed)\")\n",
    "print(f\"Aesthetic Weight: {STATIC_AESTHETIC_WEIGHT} (fixed)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run experiment with static weights\n",
    "static_history, static_population = run_experiment(\n",
    "    evaluator=static_evaluator,\n",
    "    experiment_name=\"exp1_1_static\",\n",
    "    results_array=ALL_RESULTS,\n",
    "    max_generations=MAX_GENERATIONS,\n",
    "    save_every=SAVE_EVERY_N_GENERATIONS,\n",
    "    is_adaptive=False\n",
    ")\n",
    "\n",
    "# Get best genome from static experiment\n",
    "best_static_genome = max(static_population, key=lambda g: g.fitness)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 1.1 RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final Best Fitness: {best_static_genome.fitness:.4f}\")\n",
    "print(f\"Improvement over baseline: {(best_static_genome.fitness - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "print(f\"\\nBest Prompt:\")\n",
    "print(f\"  {best_static_genome.to_prompt()}\")\n",
    "print(f\"\\nPositive Modifiers: {best_static_genome.positive_modifiers}\")\n",
    "print(f\"Negative Modifiers: {best_static_genome.negative_modifiers}\")\n",
    "print(f\"\\nTotal images generated so far: {len(ALL_RESULTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize static experiment convergence\n",
    "fig_static = visualize_results(\n",
    "    static_history, \n",
    "    baseline_score,\n",
    "    title=\"Experiment 1.1: Static Weights Evolution\"\n",
    ")\n",
    "fig_static.savefig(OUTPUT_DIR / \"exp1_1_convergence.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Run Experiment 1.2 (Adaptive Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1.2: ADAPTIVE WEIGHTS\")\n",
    "print(f\"CLIP Weight: {INITIAL_CLIP_WEIGHT} -> {FINAL_CLIP_WEIGHT}\")\n",
    "print(f\"Aesthetic Weight: {1 - INITIAL_CLIP_WEIGHT} -> {1 - FINAL_CLIP_WEIGHT}\")\n",
    "print(\"Strategy: Start semantic-focused, end aesthetic-focused\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Re-create adaptive evaluator to reset state\n",
    "adaptive_evaluator = AdaptiveFitnessEvaluator(\n",
    "    initial_clip_weight=INITIAL_CLIP_WEIGHT,\n",
    "    final_clip_weight=FINAL_CLIP_WEIGHT,\n",
    "    max_generations=MAX_GENERATIONS\n",
    ")\n",
    "\n",
    "# Run experiment with adaptive weights\n",
    "adaptive_history, adaptive_population = run_experiment(\n",
    "    evaluator=adaptive_evaluator,\n",
    "    experiment_name=\"exp1_2_adaptive\",\n",
    "    results_array=ALL_RESULTS,\n",
    "    max_generations=MAX_GENERATIONS,\n",
    "    save_every=SAVE_EVERY_N_GENERATIONS,\n",
    "    is_adaptive=True\n",
    ")\n",
    "\n",
    "# Get best genome from adaptive experiment\n",
    "best_adaptive_genome = max(adaptive_population, key=lambda g: g.fitness)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 1.2 RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final Best Fitness: {best_adaptive_genome.fitness:.4f}\")\n",
    "print(f\"Improvement over baseline: {(best_adaptive_genome.fitness - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "print(f\"\\nBest Prompt:\")\n",
    "print(f\"  {best_adaptive_genome.to_prompt()}\")\n",
    "print(f\"\\nPositive Modifiers: {best_adaptive_genome.positive_modifiers}\")\n",
    "print(f\"Negative Modifiers: {best_adaptive_genome.negative_modifiers}\")\n",
    "print(f\"\\nTotal images generated: {len(ALL_RESULTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize adaptive experiment convergence\n",
    "fig_adaptive = visualize_results(\n",
    "    adaptive_history, \n",
    "    baseline_score,\n",
    "    title=\"Experiment 1.2: Adaptive Weights Evolution\"\n",
    ")\n",
    "fig_adaptive.savefig(OUTPUT_DIR / \"exp1_2_convergence.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Comparison & Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: STATIC vs ADAPTIVE WEIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Side-by-side convergence comparison\n",
    "fig_comparison = compare_experiments(\n",
    "    static_history,\n",
    "    adaptive_history,\n",
    "    baseline_score,\n",
    "    exp1_name=\"Static (1.1)\",\n",
    "    exp2_name=\"Adaptive (1.2)\"\n",
    ")\n",
    "fig_comparison.savefig(OUTPUT_DIR / \"comparison_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Extract final fitness values for statistical comparison\n",
    "static_final = [g.fitness for g in static_population]\n",
    "adaptive_final = [g.fitness for g in adaptive_population]\n",
    "\n",
    "# Statistical tests\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Independent samples t-test\n",
    "t_stat, p_value = stats.ttest_ind(static_final, adaptive_final)\n",
    "print(f\"\\nIndependent t-test:\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Significant (p < 0.05): {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Mann-Whitney U test (non-parametric alternative)\n",
    "u_stat, u_pvalue = stats.mannwhitneyu(static_final, adaptive_final, alternative='two-sided')\n",
    "print(f\"\\nMann-Whitney U test:\")\n",
    "print(f\"  U-statistic: {u_stat:.4f}\")\n",
    "print(f\"  p-value: {u_pvalue:.4f}\")\n",
    "print(f\"  Significant (p < 0.05): {'Yes' if u_pvalue < 0.05 else 'No'}\")\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nBaseline:\")\n",
    "print(f\"  Fitness: {baseline_score:.4f}\")\n",
    "\n",
    "print(f\"\\nStatic Weights (Exp 1.1):\")\n",
    "print(f\"  Mean:   {np.mean(static_final):.4f}\")\n",
    "print(f\"  Std:    {np.std(static_final):.4f}\")\n",
    "print(f\"  Min:    {np.min(static_final):.4f}\")\n",
    "print(f\"  Max:    {np.max(static_final):.4f}\")\n",
    "print(f\"  Median: {np.median(static_final):.4f}\")\n",
    "\n",
    "print(f\"\\nAdaptive Weights (Exp 1.2):\")\n",
    "print(f\"  Mean:   {np.mean(adaptive_final):.4f}\")\n",
    "print(f\"  Std:    {np.std(adaptive_final):.4f}\")\n",
    "print(f\"  Min:    {np.min(adaptive_final):.4f}\")\n",
    "print(f\"  Max:    {np.max(adaptive_final):.4f}\")\n",
    "print(f\"  Median: {np.median(adaptive_final):.4f}\")\n",
    "\n",
    "# Effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(static_final) - 1) * np.var(static_final) + \n",
    "                      (len(adaptive_final) - 1) * np.var(adaptive_final)) / \n",
    "                     (len(static_final) + len(adaptive_final) - 2))\n",
    "cohens_d = (np.mean(adaptive_final) - np.mean(static_final)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "print(f\"\\nEffect Size (Cohen's d): {cohens_d:.4f}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_interpretation = \"negligible\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_interpretation = \"small\"\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    effect_interpretation = \"medium\"\n",
    "else:\n",
    "    effect_interpretation = \"large\"\n",
    "print(f\"  Interpretation: {effect_interpretation} effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "box_data = [static_final, adaptive_final]\n",
    "bp = ax.boxplot(box_data, labels=['Static Weights\\n(Exp 1.1)', 'Adaptive Weights\\n(Exp 1.2)'],\n",
    "                patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "\n",
    "# Add baseline line\n",
    "ax.axhline(y=baseline_score, color='orange', linestyle='--', \n",
    "           linewidth=2, label=f'Baseline ({baseline_score:.4f})')\n",
    "\n",
    "ax.set_ylabel('Fitness Score')\n",
    "ax.set_title('Final Population Fitness Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"boxplot_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating final comparison images...\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "# Generate final images with consistent seed for fair comparison\n",
    "COMPARISON_SEED = 12345\n",
    "\n",
    "# Baseline image (already generated, but regenerate with comparison seed)\n",
    "print(\"Generating baseline image...\")\n",
    "baseline_final_image, baseline_final_score = generate_final_image(\n",
    "    factory.create_empty(BASE_PROMPT), \n",
    "    seed=COMPARISON_SEED\n",
    ")\n",
    "\n",
    "# Best static image\n",
    "print(\"Generating best static weights image...\")\n",
    "static_final_image, static_final_score = generate_final_image(\n",
    "    best_static_genome, \n",
    "    seed=COMPARISON_SEED\n",
    ")\n",
    "\n",
    "# Best adaptive image  \n",
    "print(\"Generating best adaptive weights image...\")\n",
    "adaptive_final_image, adaptive_final_score = generate_final_image(\n",
    "    best_adaptive_genome, \n",
    "    seed=COMPARISON_SEED\n",
    ")\n",
    "\n",
    "print(\"Image generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side visual comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Baseline\n",
    "axes[0].imshow(baseline_final_image)\n",
    "axes[0].set_title(f\"Baseline\\nFitness: {baseline_final_score:.4f}\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Static best\n",
    "axes[1].imshow(static_final_image)\n",
    "improvement_static = (static_final_score - baseline_final_score) / baseline_final_score * 100\n",
    "axes[1].set_title(f\"Static Weights (Exp 1.1)\\nFitness: {static_final_score:.4f} (+{improvement_static:.1f}%)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Adaptive best\n",
    "axes[2].imshow(adaptive_final_image)\n",
    "improvement_adaptive = (adaptive_final_score - baseline_final_score) / baseline_final_score * 100\n",
    "axes[2].set_title(f\"Adaptive Weights (Exp 1.2)\\nFitness: {adaptive_final_score:.4f} (+{improvement_adaptive:.1f}%)\", fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Visual Comparison: {BASE_PROMPT}\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"visual_comparison.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save individual images\n",
    "baseline_final_image.save(OUTPUT_DIR / \"final_baseline.jpg\")\n",
    "static_final_image.save(OUTPUT_DIR / \"final_static_best.jpg\")\n",
    "adaptive_final_image.save(OUTPUT_DIR / \"final_adaptive_best.jpg\")\n",
    "\n",
    "print(\"\\nImages saved to output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evolved prompts for comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"EVOLVED PROMPTS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nBASELINE PROMPT:\")\n",
    "print(f\"  {BASE_PROMPT}\")\n",
    "\n",
    "print(f\"\\nSTATIC WEIGHTS BEST PROMPT:\")\n",
    "print(f\"  {best_static_genome.to_prompt()}\")\n",
    "print(f\"  Positive modifiers: {best_static_genome.positive_modifiers}\")\n",
    "print(f\"  Negative modifiers: {best_static_genome.negative_modifiers}\")\n",
    "\n",
    "print(f\"\\nADAPTIVE WEIGHTS BEST PROMPT:\")\n",
    "print(f\"  {best_adaptive_genome.to_prompt()}\")\n",
    "print(f\"  Positive modifiers: {best_adaptive_genome.positive_modifiers}\")\n",
    "print(f\"  Negative modifiers: {best_adaptive_genome.negative_modifiers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Export Results for IEEE Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results for IEEE paper\n",
    "print(\"Compiling results for IEEE paper export...\")\n",
    "\n",
    "# Convert numpy types to Python native types for JSON serialization\n",
    "def to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_native(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "# Prepare results dictionary\n",
    "results = {\n",
    "    \"metadata\": {\n",
    "        \"experiment\": \"1_prompt_enhancement\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"model\": MODEL_NAME\n",
    "    },\n",
    "    \"configuration\": {\n",
    "        \"population_size\": POPULATION_SIZE,\n",
    "        \"max_generations\": MAX_GENERATIONS,\n",
    "        \"elite_size\": ELITE_SIZE,\n",
    "        \"mutation_rate\": MUTATION_RATE,\n",
    "        \"max_positive_modifiers\": MAX_POSITIVE_MODIFIERS,\n",
    "        \"max_negative_modifiers\": MAX_NEGATIVE_MODIFIERS\n",
    "    },\n",
    "    \"baseline\": {\n",
    "        \"prompt\": BASE_PROMPT,\n",
    "        \"fitness\": float(baseline_score)\n",
    "    },\n",
    "    \"static_weights\": {\n",
    "        \"clip_weight\": STATIC_CLIP_WEIGHT,\n",
    "        \"aesthetic_weight\": STATIC_AESTHETIC_WEIGHT,\n",
    "        \"final_best_fitness\": float(max(static_final)),\n",
    "        \"final_avg_fitness\": float(np.mean(static_final)),\n",
    "        \"final_std_fitness\": float(np.std(static_final)),\n",
    "        \"improvement_percent\": float((max(static_final) - baseline_score) / baseline_score * 100),\n",
    "        \"best_prompt\": best_static_genome.to_prompt(),\n",
    "        \"best_positive_modifiers\": best_static_genome.positive_modifiers,\n",
    "        \"best_negative_modifiers\": best_static_genome.negative_modifiers,\n",
    "        \"convergence_history\": to_native(static_history)\n",
    "    },\n",
    "    \"adaptive_weights\": {\n",
    "        \"initial_clip_weight\": INITIAL_CLIP_WEIGHT,\n",
    "        \"final_clip_weight\": FINAL_CLIP_WEIGHT,\n",
    "        \"final_best_fitness\": float(max(adaptive_final)),\n",
    "        \"final_avg_fitness\": float(np.mean(adaptive_final)),\n",
    "        \"final_std_fitness\": float(np.std(adaptive_final)),\n",
    "        \"improvement_percent\": float((max(adaptive_final) - baseline_score) / baseline_score * 100),\n",
    "        \"best_prompt\": best_adaptive_genome.to_prompt(),\n",
    "        \"best_positive_modifiers\": best_adaptive_genome.positive_modifiers,\n",
    "        \"best_negative_modifiers\": best_adaptive_genome.negative_modifiers,\n",
    "        \"convergence_history\": to_native(adaptive_history)\n",
    "    },\n",
    "    \"statistical_tests\": {\n",
    "        \"t_test\": {\n",
    "            \"t_statistic\": float(t_stat),\n",
    "            \"p_value\": float(p_value),\n",
    "            \"significant\": bool(p_value < 0.05)\n",
    "        },\n",
    "        \"mann_whitney_u\": {\n",
    "            \"u_statistic\": float(u_stat),\n",
    "            \"p_value\": float(u_pvalue),\n",
    "            \"significant\": bool(u_pvalue < 0.05)\n",
    "        },\n",
    "        \"effect_size\": {\n",
    "            \"cohens_d\": float(cohens_d),\n",
    "            \"interpretation\": effect_interpretation\n",
    "        }\n",
    "    },\n",
    "    \"comparison_summary\": {\n",
    "        \"winner\": \"adaptive\" if np.mean(adaptive_final) > np.mean(static_final) else \"static\",\n",
    "        \"static_mean\": float(np.mean(static_final)),\n",
    "        \"adaptive_mean\": float(np.mean(adaptive_final)),\n",
    "        \"difference\": float(np.mean(adaptive_final) - np.mean(static_final)),\n",
    "        \"relative_improvement\": float((np.mean(adaptive_final) - np.mean(static_final)) / np.mean(static_final) * 100) if np.mean(static_final) > 0 else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_path = OUTPUT_DIR / \"results_experiment_1.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "# Print summary for paper\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY FOR IEEE PAPER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. BASELINE PERFORMANCE\")\n",
    "print(f\"   - Fitness: {baseline_score:.4f}\")\n",
    "\n",
    "print(f\"\\n2. EXPERIMENT 1.1 (STATIC WEIGHTS)\")\n",
    "print(f\"   - Best Fitness: {max(static_final):.4f}\")\n",
    "print(f\"   - Mean Fitness: {np.mean(static_final):.4f} (+/- {np.std(static_final):.4f})\")\n",
    "print(f\"   - Improvement: +{(max(static_final) - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n3. EXPERIMENT 1.2 (ADAPTIVE WEIGHTS)\")\n",
    "print(f\"   - Best Fitness: {max(adaptive_final):.4f}\")\n",
    "print(f\"   - Mean Fitness: {np.mean(adaptive_final):.4f} (+/- {np.std(adaptive_final):.4f})\")\n",
    "print(f\"   - Improvement: +{(max(adaptive_final) - baseline_score) / baseline_score * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n4. STATISTICAL SIGNIFICANCE\")\n",
    "print(f\"   - t-test p-value: {p_value:.4f} ({'significant' if p_value < 0.05 else 'not significant'})\")\n",
    "print(f\"   - Cohen's d: {cohens_d:.4f} ({effect_interpretation} effect)\")\n",
    "\n",
    "winner = \"Adaptive\" if np.mean(adaptive_final) > np.mean(static_final) else \"Static\"\n",
    "print(f\"\\n5. CONCLUSION\")\n",
    "print(f\"   - Better approach: {winner} Weights\")\n",
    "print(f\"   - Difference in mean fitness: {abs(np.mean(adaptive_final) - np.mean(static_final)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table for paper\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LaTeX TABLE FOR IEEE PAPER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "latex_table = r\"\"\"\n",
    "\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Experiment 1: Prompt Enhancement Results}\n",
    "\\label{tab:exp1_results}\n",
    "\\begin{tabular}{lccc}\n",
    "\\hline\n",
    "\\textbf{Metric} & \\textbf{Baseline} & \\textbf{Static} & \\textbf{Adaptive} \\\\\n",
    "\\hline\n",
    "Best Fitness & %.4f & %.4f & %.4f \\\\\n",
    "Mean Fitness & - & %.4f & %.4f \\\\\n",
    "Std Dev & - & %.4f & %.4f \\\\\n",
    "Improvement (\\%%) & - & +%.2f\\%% & +%.2f\\%% \\\\\n",
    "\\hline\n",
    "\\multicolumn{4}{l}{\\textit{Statistical Test: t=%.4f, p=%.4f}} \\\\\n",
    "\\multicolumn{4}{l}{\\textit{Effect Size: Cohen's d=%.4f (%s)}} \\\\\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\" % (\n",
    "    baseline_score, max(static_final), max(adaptive_final),\n",
    "    np.mean(static_final), np.mean(adaptive_final),\n",
    "    np.std(static_final), np.std(adaptive_final),\n",
    "    (max(static_final) - baseline_score) / baseline_score * 100,\n",
    "    (max(adaptive_final) - baseline_score) / baseline_score * 100,\n",
    "    t_stat, p_value, cohens_d, effect_interpretation\n",
    ")\n",
    "\n",
    "print(latex_table)\n",
    "\n",
    "# Save LaTeX table\n",
    "with open(OUTPUT_DIR / \"table_experiment_1.tex\", 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"\\nLaTeX table saved to: {OUTPUT_DIR / 'table_experiment_1.tex'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 1 COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nOutput files saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for f in sorted(OUTPUT_DIR.glob(\"*\")):\n",
    "    if f.is_file():\n",
    "        print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nExperiment subdirectories:\")\n",
    "for d in sorted(OUTPUT_DIR.glob(\"exp*\")):\n",
    "    if d.is_dir():\n",
    "        print(f\"  - {d.name}/\")\n",
    "\n",
    "logger.info(\"Experiment 1 completed successfully.\")\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Return All Results Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ALL RESULTS ARRAY\n",
    "# =============================================================================\n",
    "# This cell returns the complete results array with all generated images,\n",
    "# prompts, and fitness scores.\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ALL RESULTS ARRAY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal entries in ALL_RESULTS: {len(ALL_RESULTS)}\")\n",
    "\n",
    "# Save ALL_RESULTS to JSON file\n",
    "all_results_path = OUTPUT_DIR / \"all_results_array.json\"\n",
    "save_json(ALL_RESULTS, str(all_results_path))\n",
    "print(f\"All results saved to: {all_results_path}\")\n",
    "\n",
    "# Display summary statistics\n",
    "exp1_1_results = [r for r in ALL_RESULTS if r['experiment'] == 'exp1_1_static']\n",
    "exp1_2_results = [r for r in ALL_RESULTS if r['experiment'] == 'exp1_2_adaptive']\n",
    "\n",
    "print(f\"\\nExperiment 1.1 (Static): {len(exp1_1_results)} images\")\n",
    "print(f\"Experiment 1.2 (Adaptive): {len(exp1_2_results)} images\")\n",
    "\n",
    "# Get top 10 results by fitness across all experiments\n",
    "sorted_results = sorted(ALL_RESULTS, key=lambda x: x['fitness'], reverse=True)\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"TOP 10 RESULTS BY FITNESS:\")\n",
    "print(\"-\" * 60)\n",
    "for i, result in enumerate(sorted_results[:10], 1):\n",
    "    print(f\"\\n{i}. Fitness: {result['fitness']:.4f}\")\n",
    "    print(f\"   Experiment: {result['experiment']}\")\n",
    "    print(f\"   Generation: {result['generation']}\")\n",
    "    print(f\"   Prompt: {result['prompt'][:80]}...\")\n",
    "    print(f\"   Image: {result['image_path'].split('/')[-1] if result['image_path'] else 'N/A'}\")\n",
    "\n",
    "# Display the array structure\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"ARRAY STRUCTURE (sample entry):\")\n",
    "print(\"-\" * 60)\n",
    "if ALL_RESULTS:\n",
    "    sample = ALL_RESULTS[0]\n",
    "    for key, value in sample.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"  {key}: {value[:3]}...\" if len(value) > 3 else f\"  {key}: {value}\")\n",
    "        elif isinstance(value, str) and len(value) > 50:\n",
    "            print(f\"  {key}: {value[:50]}...\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ACCESS ALL_RESULTS VARIABLE FOR FULL DATA\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return ALL_RESULTS array for programmatic access\n",
    "# This cell outputs the complete array containing all experimental data\n",
    "\n",
    "ALL_RESULTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
